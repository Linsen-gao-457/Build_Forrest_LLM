{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linsen-gao-457/Build_Forrest_LLM/blob/main/Finetune%20to%20follow%20instructions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29-FMDLV0mfj"
      },
      "source": [
        "# Prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgk6FWAkjWJU",
        "outputId": "03c438fc-a94d-47cb-e0ee-2cdb4cb6c91a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of entries: 1100\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import urllib\n",
        "def download_and_load_file(file_path, url):\n",
        "  if not os.path.exists(file_path):\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "      text_data = response.read().decode(\"utf-8\")\n",
        "    with open(file_path, \"w\", encoding = \"utf-8\") as file:\n",
        "      file.write(text_data)\n",
        "  else:\n",
        "    with open(file_path, \"r\", encoding = \"utf-8\") as file:\n",
        "      text_data = file.read()\n",
        "  return json.loads(text_data)\n",
        "\n",
        "file_path = \"instruction-data.json\"\n",
        "url = (\n",
        "\"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
        "\"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        ")\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"Number of entries:\", len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vRLgHB6GrRfb"
      },
      "outputs": [],
      "source": [
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "                      f\"Below is an instruction that describes a task. \"\n",
        "                      f\"Write a response that appropriately completes the request.\"\n",
        "                      f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "                      )\n",
        "    input_text = (\n",
        "                  f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "                  )\n",
        "    return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSYKgz_mvTFC",
        "outputId": "fd43022b-2344-4d86-f33e-f11fc905776d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Identify the correct spelling of the following word.\n",
            "\n",
            "### Input:\n",
            "Ocassion\n",
            "\n",
            "### Response:\n",
            "The correct spelling is 'Occasion.'\n"
          ]
        }
      ],
      "source": [
        "model_input = format_input(data[50])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
        "print(model_input + desired_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Cfp5yacvbSn",
        "outputId": "5e788b28-945c-4949-b4d4-d379ee4f1e7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data size: 935\n",
            "Test data size: 110\n",
            "Validation data size: 55\n"
          ]
        }
      ],
      "source": [
        "train_portion = int(len(data)*0.85)\n",
        "test_portion = int(len(data)*0.10)\n",
        "val_portion = 1-train_portion-test_portion\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion+test_portion]\n",
        "val_data = data[train_portion+test_portion:]\n",
        "print(\"Train data size:\", len(train_data))\n",
        "print(\"Test data size:\", len(test_data))\n",
        "print(\"Validation data size:\", len(val_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fdACpIcdxcft"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "class InstructionDataset(Dataset):\n",
        "  def __init__(self, data, tokenizer):\n",
        "    self.data = data\n",
        "    self.encoded_texts = []\n",
        "    for entry in data:\n",
        "      instruction_plus_input = format_input(entry)\n",
        "      response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "      full_text = instruction_plus_input + response_text\n",
        "      self.encoded_texts.append(\n",
        "      tokenizer.encode(full_text)\n",
        "      )\n",
        "  def __getitem__(self, index):\n",
        "    return self.encoded_texts[index]\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PBsYUExl8VdV"
      },
      "outputs": [],
      "source": [
        "def custom_collate_draft_1(\n",
        "    batch, pad_token_id =50256,\n",
        "    device = \"cpu\"\n",
        "):\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "    inputs_lst=[]\n",
        "    for item in batch:\n",
        "      new_item = item.copy()\n",
        "      new_item += [pad_token_id]\n",
        "      padded = (\n",
        "          new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
        "      )\n",
        "      inputs = torch.tensor(padded[:-1])\n",
        "      inputs_lst.append(inputs)\n",
        "\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    return inputs_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "u_F5VRPoNX4L"
      },
      "outputs": [],
      "source": [
        "def custom_collate_draft_ex(\n",
        "    batch, pad_token_id =50256,\n",
        "    device = \"cpu\"\n",
        "):\n",
        "    batch_max_length = max(len(item) for item in batch)\n",
        "    inputs_lst=[]\n",
        "    for item in batch:\n",
        "      new_item = item.copy()\n",
        "      padded = (\n",
        "          new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
        "      )\n",
        "      inputs_lst.append(torch.tensor(padded))\n",
        "\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    return inputs_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_qUQbUR-sqi",
        "outputId": "cc4dc440-1663-4934-a14a-e55421625efc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n"
          ]
        }
      ],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "batch = (\n",
        "inputs_1,\n",
        "inputs_2,\n",
        "inputs_3\n",
        ")\n",
        "print(custom_collate_draft_1(batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll8dPoUzKlei",
        "outputId": "113c078e-01d4-42ab-b6e9-cea9284048ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256, 50256, 50256, 50256],\n",
            "        [    8,     9, 50256, 50256, 50256]])\n"
          ]
        }
      ],
      "source": [
        "def custom_collate_draft_2(batch, pad_token_id = 50256, device = \"cpu\"):\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "    inputs_lst, targets_lst = [],[]\n",
        "    for item in batch:\n",
        "      new_item = item.copy()\n",
        "      new_item += [pad_token_id]\n",
        "      padded = (new_item + [pad_token_id]*(batch_max_length-len(new_item)))\n",
        "      inputs = torch.tensor(padded[:-1])\n",
        "      targets = torch.tensor(padded[1:])\n",
        "      inputs_lst.append(inputs)\n",
        "      targets_lst.append(targets)\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "    return inputs_tensor, targets_tensor\n",
        "\n",
        "\n",
        "inputs, targets = custom_collate_draft_2(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JZ4XZPpjWg7b"
      },
      "outputs": [],
      "source": [
        "def custom_collate_fn(\n",
        "    batch, pad_token_id =50256,ignore_index = -100, allowed_max_length = None, device = \"cpu\"\n",
        "):\n",
        "  batch_max_length = max(len(item)+1 for item in batch)\n",
        "  inputs_lst, targets_lst = [],[]\n",
        "  for item in batch:\n",
        "    new_item = item.copy()\n",
        "    new_item += [pad_token_id]\n",
        "    padded = (new_item + [pad_token_id]*(batch_max_length-len(new_item)))\n",
        "    inputs = torch.tensor(padded[:-1])\n",
        "    targets = torch.tensor(padded[1:])\n",
        "    mask = targets == pad_token_id\n",
        "    indices = torch.nonzero(mask).squeeze()\n",
        "    if indices.numel() > 1:\n",
        "      targets[indices[1:]] = ignore_index\n",
        "    if allowed_max_length is not None:\n",
        "      inputs = inputs[:allowed_max_length]\n",
        "      targets = targets[:allowed_max_length]\n",
        "\n",
        "    inputs_lst.append(inputs)\n",
        "    targets_lst.append(targets)\n",
        "\n",
        "  inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "  targets_tensor = torch.stack(targets_lst).to(device)\n",
        "  return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jeGnK8Faxtk",
        "outputId": "ed933b91-f8d0-4e2c-f0d7-a58045218b8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256,  -100,  -100,  -100],\n",
            "        [    8,     9, 50256,  -100,  -100]])\n"
          ]
        }
      ],
      "source": [
        "inputs, targets = custom_collate_fn(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-EVzpj9bMsM",
        "outputId": "19344e25-59ab-4592-ad6e-3a0b97009528"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.1269)\n"
          ]
        }
      ],
      "source": [
        "logits_1 = torch.tensor(\n",
        "[[-1.0, 1.0],\n",
        "[-0.5, 1.5]]\n",
        ")\n",
        "targets_1 = torch.tensor([0, 1]) #\n",
        "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
        "print(loss_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ee94VrLduDz",
        "outputId": "06046ead-a0be-43c0-a5ed-a452c87df5a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.7936)\n"
          ]
        }
      ],
      "source": [
        "logits_2 = torch.tensor(\n",
        "[[-1.0, 1.0],\n",
        "[-0.5, 1.5],\n",
        "[-0.5, 1.5]]\n",
        ")\n",
        "targets_2 = torch.tensor([0, 1, 1])\n",
        "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
        "print(loss_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XnOGwW4d7HF",
        "outputId": "4e383d18-77cd-4639-879b-af23686228eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.1269)\n",
            "loss_1 == loss_3: tensor(True)\n"
          ]
        }
      ],
      "source": [
        "targets_3 = torch.tensor([0, 1, -100])\n",
        "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
        "print(loss_3)\n",
        "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIPySsMNfAas",
        "outputId": "8fdad50a-0826-477d-ca89-525910f9f300"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Yr9cxZNgjSbj"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "customized_collate_fn = partial(\n",
        "custom_collate_fn,\n",
        "device=device,\n",
        "allowed_max_length=1024\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mDGkFbun96U",
        "outputId": "67dd82a9-19e4-48d2-e35e-e84a946b94a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n",
            "[50256]\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken\n",
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiyK57mFloiJ",
        "outputId": "c2a58de2-aa8b-4222-f4a3-516c283f26b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loader:\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 57]) torch.Size([8, 57])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "train_dataset,\n",
        "batch_size=batch_size,\n",
        "collate_fn=customized_collate_fn,\n",
        "shuffle=True,\n",
        "drop_last=True,\n",
        "num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "val_dataset,\n",
        "batch_size=batch_size,\n",
        "collate_fn=customized_collate_fn,\n",
        "shuffle=False,\n",
        "drop_last=False,\n",
        "num_workers=num_workers\n",
        ")\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "test_dataset,\n",
        "batch_size=batch_size,\n",
        "collate_fn=customized_collate_fn,\n",
        "shuffle=False,\n",
        "drop_last=False,\n",
        "num_workers=num_workers\n",
        ")\n",
        "\n",
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        "  print(inputs.shape, targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD7U-D6mwfrX"
      },
      "source": [
        "# load provious code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vax5r1Ftoixd",
        "outputId": "cf5bbac5-d686-4d0a-c72f-299f1d790a3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "                      IN\n",
            "==================================================\n",
            "\n",
            "Input text: Hello, I am\n",
            "Encoded input text: [15496, 11, 314, 716]\n",
            "encoded_tensor.shape: torch.Size([1, 4])\n",
            "\n",
            "\n",
            "==================================================\n",
            "                      OUT\n",
            "==================================================\n",
            "\n",
            "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267,\n",
            "         49706, 43231, 47062, 34657]])\n",
            "Output length: 14\n",
            "Output text: Hello, I am Featureiman Byeswickattribute argue logger Normandy Compton analogous\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by n_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    GPT_CONFIG_124M = {\n",
        "        \"vocab_size\": 50257,     # Vocabulary size\n",
        "        \"context_length\": 1024,  # Context length\n",
        "        \"emb_dim\": 768,          # Embedding dimension\n",
        "        \"n_heads\": 12,           # Number of attention heads\n",
        "        \"n_layers\": 12,          # Number of layers\n",
        "        \"drop_rate\": 0.1,        # Dropout rate\n",
        "        \"qkv_bias\": False        # Query-Key-Value bias\n",
        "    }\n",
        "\n",
        "    torch.manual_seed(123)\n",
        "    model = GPTModel(GPT_CONFIG_124M)\n",
        "    model.eval()\n",
        "\n",
        "    start_context = \"Hello, I am\"\n",
        "\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    encoded = tokenizer.encode(start_context)\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "\n",
        "    print(f\"\\n{50*'='}\\n{22*' '}IN\\n{50*'='}\")\n",
        "    print(\"\\nInput text:\", start_context)\n",
        "    print(\"Encoded input text:\", encoded)\n",
        "    print(\"encoded_tensor.shape:\", encoded_tensor.shape)\n",
        "\n",
        "    out = generate_text_simple(\n",
        "        model=model,\n",
        "        idx=encoded_tensor,\n",
        "        max_new_tokens=10,\n",
        "        context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        "    )\n",
        "    decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
        "\n",
        "    print(f\"\\n\\n{50*'='}\\n{22*' '}OUT\\n{50*'='}\")\n",
        "    print(\"\\nOutput:\", out)\n",
        "    print(\"Output length:\", len(out[0]))\n",
        "    print(\"Output text:\", decoded_text)\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right, dtype=left.dtype))\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "# import requests\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def download_and_load_gpt2(model_size, models_dir):\n",
        "    # Validate model size\n",
        "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
        "    if model_size not in allowed_sizes:\n",
        "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
        "\n",
        "    # Define paths\n",
        "    model_dir = os.path.join(models_dir, model_size)\n",
        "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
        "    backup_base_url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\"\n",
        "    filenames = [\n",
        "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
        "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
        "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
        "    ]\n",
        "\n",
        "    # Download files\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    for filename in filenames:\n",
        "        file_url = os.path.join(base_url, model_size, filename)\n",
        "        backup_url = os.path.join(backup_base_url, model_size, filename)\n",
        "        file_path = os.path.join(model_dir, filename)\n",
        "        download_file(file_url, file_path, backup_url)\n",
        "\n",
        "    # Load settings and params\n",
        "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
        "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\"), \"r\", encoding=\"utf-8\"))\n",
        "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
        "\n",
        "    return settings, params\n",
        "def download_file(url, destination, backup_url=None):\n",
        "    def _attempt_download(download_url):\n",
        "        with urllib.request.urlopen(download_url) as response:\n",
        "            # Get the total file size from headers, defaulting to 0 if not present\n",
        "            file_size = int(response.headers.get(\"Content-Length\", 0))\n",
        "\n",
        "            # Check if file exists and has the same size\n",
        "            if os.path.exists(destination):\n",
        "                file_size_local = os.path.getsize(destination)\n",
        "                if file_size == file_size_local:\n",
        "                    print(f\"File already exists and is up-to-date: {destination}\")\n",
        "                    return True  # Indicate success without re-downloading\n",
        "\n",
        "            block_size = 1024  # 1 Kilobyte\n",
        "\n",
        "            # Initialize the progress bar with total file size\n",
        "            progress_bar_description = os.path.basename(download_url)\n",
        "            with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
        "                with open(destination, \"wb\") as file:\n",
        "                    while True:\n",
        "                        chunk = response.read(block_size)\n",
        "                        if not chunk:\n",
        "                            break\n",
        "                        file.write(chunk)\n",
        "                        progress_bar.update(len(chunk))\n",
        "            return True\n",
        "\n",
        "    try:\n",
        "        if _attempt_download(url):\n",
        "            return\n",
        "    except (urllib.error.HTTPError, urllib.error.URLError):\n",
        "        if backup_url is not None:\n",
        "            print(f\"Primary URL ({url}) failed. Attempting backup URL: {backup_url}\")\n",
        "            try:\n",
        "                if _attempt_download(backup_url):\n",
        "                    return\n",
        "            except urllib.error.HTTPError:\n",
        "                pass\n",
        "\n",
        "        error_message = (\n",
        "            f\"Failed to download from both primary URL ({url})\"\n",
        "            f\"{' and backup URL (' + backup_url + ')' if backup_url else ''}.\"\n",
        "            \"\\nCheck your internet connection or the file availability.\\n\"\n",
        "            \"For help, visit: https://github.com/rasbt/LLMs-from-scratch/discussions/273\"\n",
        "        )\n",
        "        print(error_message)\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
        "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
        "\n",
        "    # Iterate over each variable in the checkpoint\n",
        "    for name, _ in tf.train.list_variables(ckpt_path):\n",
        "        # Load the variable and remove singleton dimensions\n",
        "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
        "\n",
        "        # Process the variable name to extract relevant parts\n",
        "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
        "\n",
        "        # Identify the target dictionary for the variable\n",
        "        target_dict = params\n",
        "        if variable_name_parts[0].startswith(\"h\"):\n",
        "            layer_number = int(variable_name_parts[0][1:])\n",
        "            target_dict = params[\"blocks\"][layer_number]\n",
        "\n",
        "        # Recursively access or create nested dictionaries\n",
        "        for key in variable_name_parts[1:-1]:\n",
        "            target_dict = target_dict.setdefault(key, {})\n",
        "\n",
        "        # Assign the variable array to the last key\n",
        "        last_key = variable_name_parts[-1]\n",
        "        target_dict[last_key] = variable_array\n",
        "\n",
        "    return params\n",
        "\n",
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qapO7xSjv55K"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "  input_batch = input_batch.to(device)\n",
        "  target_batch = target_batch.to(device)\n",
        "  logits = model(input_batch)\n",
        "  logits_flat = logits.flatten(0,1)\n",
        "  targets_flat = target_batch.flatten()\n",
        "  loss = F.cross_entropy(logits_flat, targets_flat)\n",
        "  return loss\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()\n",
        "\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "  encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "  return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "  flat = token_ids.squeeze(0)\n",
        "  return tokenizer.decode(flat.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75fUEHfnwlkY"
      },
      "source": [
        "# Finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p-nR7eepXN6",
        "outputId": "f10f604e-3c4f-4e53-929d-107ab2a95011"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 117kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.07MiB/s]\n",
            "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 238kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [04:35<00:00, 5.15MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 13.6MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 927k/927k [00:00<00:00, 1.07MiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 835kiB/s]\n"
          ]
        }
      ],
      "source": [
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": True\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "\"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "\"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "\"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "\"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "\n",
        "settings, params = download_and_load_gpt2(\n",
        "model_size=model_size,\n",
        "models_dir=\"gpt2\"\n",
        ")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WchzL3KTp0ch",
        "outputId": "3305d863-6c53-4135-88e3-4e7ae2c2cbf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "iawpdfrAp6vf"
      },
      "outputs": [],
      "source": [
        "token_ids = generate(\n",
        "model=model,\n",
        "idx=text_to_token_ids(input_text, tokenizer),\n",
        "max_new_tokens=35,\n",
        "context_size=BASE_CONFIG[\"context_length\"],\n",
        "eos_id=50256,\n",
        ")\n",
        "generated_text = token_ids_to_text(token_ids, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgEigJ6kr61g",
        "outputId": "bfd54005-878d-44e6-ad42-24c13d26f6ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The chef cooks the meal every day.\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the\n"
          ]
        }
      ],
      "source": [
        "response_text = (\n",
        "    generated_text[len(input_text):]\n",
        "    .replace(\"### Response:\", \"\")\n",
        "    .strip()\n",
        ")\n",
        "print(response_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Btl2zxmS04en",
        "outputId": "ef45d49c-aee0-469f-b0e6-c3c618d33330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss: 3.825909471511841\n",
            "Validation loss: 3.761934232711792\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "model.to(device)\n",
        "torch.manual_seed(123)\n",
        "with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(\n",
        "  train_loader, model, device, num_batches=5\n",
        "  )\n",
        "val_loss = calc_loss_loader(\n",
        "val_loader, model, device, num_batches=5\n",
        ")\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyPlUBI2sSJz",
        "outputId": "f47c48c5-d2a7-4140-8517-e4593ffbdf7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.489, Val loss 2.490\n",
            "Ep 1 (Step 000005): Train loss 1.180, Val loss 1.110\n",
            "Ep 1 (Step 000010): Train loss 0.885, Val loss 0.980\n",
            "Ep 1 (Step 000015): Train loss 0.901, Val loss 0.941\n",
            "Ep 1 (Step 000020): Train loss 0.819, Val loss 0.917\n",
            "Ep 1 (Step 000025): Train loss 0.778, Val loss 0.890\n",
            "Ep 1 (Step 000030): Train loss 0.821, Val loss 0.865\n",
            "Ep 1 (Step 000035): Train loss 0.741, Val loss 0.847\n",
            "Ep 1 (Step 000040): Train loss 0.707, Val loss 0.839\n",
            "Ep 1 (Step 000045): Train loss 0.664, Val loss 0.818\n",
            "Ep 1 (Step 000050): Train loss 0.712, Val loss 0.809\n",
            "Ep 1 (Step 000055): Train loss 0.784, Val loss 0.793\n",
            "Ep 1 (Step 000060): Train loss 0.753, Val loss 0.769\n",
            "Ep 1 (Step 000065): Train loss 0.676, Val loss 0.757\n",
            "Ep 1 (Step 000070): Train loss 0.583, Val loss 0.755\n",
            "Ep 1 (Step 000075): Train loss 0.590, Val loss 0.754\n",
            "Ep 1 (Step 000080): Train loss 0.647, Val loss 0.749\n",
            "Ep 1 (Step 000085): Train loss 0.548, Val loss 0.742\n",
            "Ep 1 (Step 000090): Train loss 0.596, Val loss 0.724\n",
            "Ep 1 (Step 000095): Train loss 0.539, Val loss 0.713\n",
            "Ep 1 (Step 000100): Train loss 0.542, Val loss 0.706\n",
            "Ep 1 (Step 000105): Train loss 0.599, Val loss 0.701\n",
            "Ep 1 (Step 000110): Train loss 0.596, Val loss 0.700\n",
            "Ep 1 (Step 000115): Train loss 0.552, Val loss 0.694\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The active sentence is 'The chef cooks the meal every day.'<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence\n",
            "Ep 2 (Step 000120): Train loss 0.492, Val loss 0.698\n",
            "Ep 2 (Step 000125): Train loss 0.508, Val loss 0.710\n",
            "Ep 2 (Step 000130): Train loss 0.507, Val loss 0.707\n",
            "Ep 2 (Step 000135): Train loss 0.459, Val loss 0.705\n",
            "Ep 2 (Step 000140): Train loss 0.478, Val loss 0.700\n",
            "Ep 2 (Step 000145): Train loss 0.429, Val loss 0.700\n",
            "Ep 2 (Step 000150): Train loss 0.434, Val loss 0.694\n",
            "Ep 2 (Step 000155): Train loss 0.475, Val loss 0.682\n",
            "Ep 2 (Step 000160): Train loss 0.477, Val loss 0.681\n",
            "Ep 2 (Step 000165): Train loss 0.443, Val loss 0.680\n",
            "Ep 2 (Step 000170): Train loss 0.380, Val loss 0.680\n",
            "Ep 2 (Step 000175): Train loss 0.391, Val loss 0.678\n",
            "Ep 2 (Step 000180): Train loss 0.450, Val loss 0.664\n",
            "Ep 2 (Step 000185): Train loss 0.469, Val loss 0.662\n",
            "Ep 2 (Step 000190): Train loss 0.387, Val loss 0.658\n",
            "Ep 2 (Step 000195): Train loss 0.395, Val loss 0.650\n",
            "Ep 2 (Step 000200): Train loss 0.350, Val loss 0.645\n",
            "Ep 2 (Step 000205): Train loss 0.414, Val loss 0.639\n",
            "Ep 2 (Step 000210): Train loss 0.436, Val loss 0.639\n",
            "Ep 2 (Step 000215): Train loss 0.454, Val loss 0.641\n",
            "Ep 2 (Step 000220): Train loss 0.351, Val loss 0.651\n",
            "Ep 2 (Step 000225): Train loss 0.407, Val loss 0.653\n",
            "Ep 2 (Step 000230): Train loss 0.348, Val loss 0.646\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
            "Training completed in 3.30 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 2\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "m7ryNcAhttST",
        "outputId": "759fac20-65aa-45e7-8033-2b3d3a18b9b7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "\n",
        "    ax2 = ax1.twiny()\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp4A3FXkulbm",
        "outputId": "12c0bc73-e7ed-4e65-ebb8-ca44845fada8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n",
            "\n",
            "Correct response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What type of cloud is typically associated with thunderstorms?\n",
            "\n",
            "Correct response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> A thunderstorm is a type of storm.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Name the author of 'Pride and Prejudice'.\n",
            "\n",
            "Correct response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is George Bernard Shaw.\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "\n",
        "for entry in test_data[:3]:\n",
        "    input_text = format_input(entry)\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        ")\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"-------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKQgXUtb8lFt"
      },
      "source": [
        "# AlpacaEval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejykEF1qurw3",
        "outputId": "890f111c-c9b0-4eca-a020-35a9129a4898"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 110/110 [01:06<00:00,  1.65it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    test_data[i][\"model_response\"] = response_text\n",
        "\n",
        "\n",
        "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
        "    json.dump(test_data, file, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ollama running: True\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "def check_if_running(process_name):\n",
        "    running = False\n",
        "    for proc in psutil.process_iter([\"name\"]):\n",
        "        if process_name in proc.info[\"name\"]:\n",
        "            running = True\n",
        "            break\n",
        "    return running\n",
        "ollama_running = check_if_running(\"ollama\")\n",
        "if not ollama_running:\n",
        "    raise RuntimeError(\n",
        "        \"Ollama not running. Launch ollama before proceeding.\"\n",
        "        )\n",
        "print(\"Ollama running:\", check_if_running(\"ollama\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from tqdm import tqdm\n",
        "file_path = \"instruction-data-with-response.json\"\n",
        "with open(file_path, \"r\") as file:\n",
        "    test_data = json.load(file)\n",
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "    f\"Below is an instruction that describes a task. \"\n",
        "    f\"Write a response that appropriately completes the request.\"\n",
        "    f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "    input_text = (\n",
        "    f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "    )\n",
        "    return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "def query_model(\n",
        "prompt,\n",
        "model=\"llama3\",\n",
        "url=\"http://localhost:11434/api/chat\"\n",
        "):\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"options\": {     # Settings below are required for deterministic responses\n",
        "            \"seed\": 123,\n",
        "            \"temperature\": 0,\n",
        "            \"num_ctx\": 2048\n",
        "        }\n",
        "    }\n",
        "    payload = json.dumps(data).encode(\"utf-8\")\n",
        "    request = urllib.request.Request(\n",
        "        url,\n",
        "        data=payload,\n",
        "        method=\"POST\"\n",
        "    )\n",
        "    request.add_header(\"Content-Type\", \"application/json\")\n",
        "\n",
        "    # Send the request and capture the response\n",
        "    response_data = \"\"\n",
        "    with urllib.request.urlopen(request) as response:\n",
        "        # Read and decode the response\n",
        "        while True:\n",
        "            line = response.readline().decode(\"utf-8\")\n",
        "            if not line:\n",
        "                break\n",
        "            response_json = json.loads(line)\n",
        "            response_data += response_json[\"message\"][\"content\"]\n",
        "\n",
        "    return response_data\n",
        "\n",
        "model = \"llama3\"\n",
        "result = query_model(\"What do Llamas eat?\", model)\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPZCuijB+Li/GTjP2OaTAht",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
