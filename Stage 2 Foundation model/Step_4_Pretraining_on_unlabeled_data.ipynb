{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOIJdjDSMDmdW22kNT0nnCO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linsen-gao-457/Build_Forrest_LLM/blob/main/Step_4_Pretraining_on_unlabeled_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EVeZi2hT4st2"
      },
      "outputs": [],
      "source": [
        "#import GPTModel We built in Step3\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# --- FeedForward Block ---\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),  # <- hardcoded multiplier\n",
        "            nn.GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "            nn.Dropout(cfg[\"drop_rate\"])\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "# --- Multi-Head Attention ---\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, _ = x.shape\n",
        "\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "        attn_scores = attn_scores.masked_fill(mask_bool, -1e10)\n",
        "        attn_scores = torch.clamp(attn_scores, min=-1e10, max=1e4)\n",
        "\n",
        "        scale = self.head_dim ** 0.5\n",
        "        attn_scores = attn_scores / scale\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2).contiguous()\n",
        "        context_vec = context_vec.view(b, num_tokens, self.d_out)\n",
        "        return self.out_proj(context_vec)\n",
        "\n",
        "# --- Transformer Block ---\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"]\n",
        "        )\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = nn.LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = nn.LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "        return x\n",
        "\n",
        "# --- GPT Model ---\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "        self.trf_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])] )\n",
        "        self.final_norm = nn.LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 256,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_layers\": 12,\n",
        "    \"n_heads\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od5nbgyiJfFT",
        "outputId": "44ef62ac-c4b5-47e1-af69-b2f98668d44d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_McNDtXtMqNc",
        "outputId": "cfc41a81-d53e-4038-9785-ba4c5e267815"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluating generative text models"
      ],
      "metadata": {
        "id": "5Ji-cPhkUdB2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Generation"
      ],
      "metadata": {
        "id": "phHH3xxEUf5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond = idx[:,-context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "    logits = logits[:, -1, :]\n",
        "    probas = torch.softmax(logits, dim = -1)\n",
        "    idx_next = torch.argmax(probas, dim = -1, keepdim =True)\n",
        "    idx = torch.cat((idx, idx_next), dim =1)\n",
        "  return idx"
      ],
      "metadata": {
        "id": "xCU1EyBiKoV9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "  encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "  return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "  flat = token_ids.squeeze(0)\n",
        "  return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "token_ids = generate_text_simple(\n",
        "    model = model,\n",
        "    idx = text_to_token_ids(start_context, tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
        "    )\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9AN1gFnM8YA",
        "outputId": "64900675-d098-44db-9319-e0a40285b5d2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Evaluation\n"
      ],
      "metadata": {
        "id": "D4JfEpY-UqlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
        "                       [40,    1107, 588]])   #  \"I really like\"]\n",
        "\n",
        "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
        "                        [1107,  588, 11311]]) #  \" really like chocolate\"]\n"
      ],
      "metadata": {
        "id": "Cr1yj0cNUvMJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  logits = model(inputs)\n",
        "probas = torch.softmax(logits, dim = -1)\n",
        "print(probas.shape)\n",
        "token_ids = torch.argmax(probas, dim = -1, keepdim = True)\n",
        "print(\"Token IDs:\\n\", token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhmbkdO9wyms",
        "outputId": "e3e0f819-1b74-4e28-a477-e7980cf7fefd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 50257])\n",
            "Token IDs:\n",
            " tensor([[[16657],\n",
            "         [  339],\n",
            "         [42826]],\n",
            "\n",
            "        [[49906],\n",
            "         [29669],\n",
            "         [41751]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
        "print(f\"Outputs batch 1:\"\n",
        "f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-DKI27lyBRY",
        "outputId": "79ba1ab6-2950-4a52-9fb0-c7629bf708bd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targets batch 1:  effort moves you\n",
            "Outputs batch 1:  Armed heNetflix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_idx = 0\n",
        "target_probas_1 = probas [text_idx, [0,1,2], targets[text_idx]]\n",
        "print(\"Text 1:\", target_probas_1)\n",
        "\n",
        "text_idx = 1\n",
        "target_probas_2 = probas [text_idx, [0,1,2], targets[text_idx]]\n",
        "print(\"Text 2:\", target_probas_2)\n",
        "\n",
        "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
        "print(\"Log probabilities:\", log_probas)\n",
        "avg_log_probas = torch.mean(log_probas)\n",
        "print(avg_log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2K5fz1fyJrv",
        "outputId": "e0434325-b6d8-4410-c37f-6e43a6c1e07b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: tensor([7.4536e-05, 3.1061e-05, 1.1563e-05])\n",
            "Text 2: tensor([1.0337e-05, 5.6771e-05, 4.7559e-06])\n",
            "Log probabilities: tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7765, -12.2561])\n",
            "tensor(-10.7940)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Logits shape\", logits.shape)\n",
        "print(\"Target shape\", targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmJ7W-es8nwl",
        "outputId": "55f7b178-1861-4633-cbdb-609c4a008a63"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape torch.Size([2, 3, 50257])\n",
            "Target shape torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits_flat = logits.flatten(0,1)\n",
        "targets_flat = targets.flatten()\n",
        "print(\"Logits shape\", logits_flat.shape)\n",
        "print(\"Target shape\", targets_flat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6SWjmqG86a4",
        "outputId": "08e51881-c90f-459f-c538-92e2072cfbf0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape torch.Size([6, 50257])\n",
            "Target shape torch.Size([6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "loss = F.cross_entropy(logits_flat, targets_flat)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "737pNJR1_ePM",
        "outputId": "7c1f8d18-3a82-47a3-e7b0-511830047922"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.7940)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "if not os.path.exists(\"the-verdict.txt\"):\n",
        "    url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
        "           \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
        "           \"the-verdict.txt\")\n",
        "    file_path = \"the-verdict.txt\"\n",
        "    urllib.request.urlretrieve(url, file_path)\n",
        "file_path = \"the-verdict.txt\"\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "  text_data = file.read()"
      ],
      "metadata": {
        "id": "JvoMh19nBfzO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "print(f\"Total characters: {total_characters}\")\n",
        "print(f\"Total tokens: {total_tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F66nkd6BsF6",
        "outputId": "8431f26f-ab0e-4310-8321-ab9a9d899873"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total characters: 20479\n",
            "Total tokens: 5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train using a small text\n",
        "train_ratio = 0.9\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]"
      ],
      "metadata": {
        "id": "VsuhuEAjB2Ps"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self, txt, tokenizer, max_length, stride) -> None:\n",
        "      self.input_ids = []\n",
        "      self.target_ids = []\n",
        "      token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "      #use a slide window to chunk the block into overlapping sequences of max_length\n",
        "      for i in range(0, len(token_ids) -max_length, stride):\n",
        "        input_chunk = token_ids[i:i+max_length]\n",
        "        target_chunk = token_ids[i+1:i+max_length+1]\n",
        "        self.input_ids.append(torch.tensor(input_chunk))\n",
        "        self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]\n",
        "def create_dataloader_v1(txt, batch_size = 4, max_length = 256, stride = 128,\n",
        "                         shuffle= True, drop_last = True, num_workers=0):\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "  dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = shuffle, drop_last = drop_last)\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "J-ikL552DI_P"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "IkllAGGfDTI0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader\")\n",
        "for x,y in train_loader:\n",
        "  print(x.shape, y.shape)\n",
        "\n",
        "print(\"\\n Validation loader:\")\n",
        "for x,y in val_loader:\n",
        "  print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3qQQXc3EwrS",
        "outputId": "0f4d0c8b-31d7-495d-c591-79220416b131"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            " Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "  input_batch = input_batch.to(device)\n",
        "  target_batch = target_batch.to(device)\n",
        "  logits = model(input_batch)\n",
        "  logits_flat = logits.flatten(0,1)\n",
        "  targets_flat = target_batch.flatten()\n",
        "  loss = F.cross_entropy(logits_flat, targets_flat)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "EDSWXK-eFy1e"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches = None):\n",
        "  total_loss = 0.\n",
        "  if len(data_loader) == 0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(data_loader))\n",
        "  for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "    if i >= num_batches:\n",
        "      break\n",
        "    loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "    total_loss += loss.item()\n",
        "  return total_loss / num_batches"
      ],
      "metadata": {
        "id": "YDdQwRUBGSiX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(train_loader, model, device)\n",
        "  val_loss = calc_loss_loader(val_loader, model, device)\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YepiSDNHDU1",
        "outputId": "a54987d6-3d19-488c-eb10-734bee385914"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 10.987582630581326\n",
            "Validation loss: 10.981103897094727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training LLM"
      ],
      "metadata": {
        "id": "25oU92pkHtDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "uo4ufAfeHmfN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XpacFxsH2FL",
        "outputId": "017a318f-27b4-470b-fcac-25ca14070223"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.835, Val loss 9.943\n",
            "Ep 1 (Step 000005): Train loss 8.076, Val loss 8.342\n",
            "Every effort moves you,,,,,,,,,,,,.                                     \n",
            "Ep 2 (Step 000010): Train loss 6.633, Val loss 7.054\n",
            "Ep 2 (Step 000015): Train loss 6.062, Val loss 6.612\n",
            "Every effort moves you,,,, and,,,,,,,,,.                                   \n",
            "Ep 3 (Step 000020): Train loss 5.655, Val loss 6.491\n",
            "Ep 3 (Step 000025): Train loss 5.632, Val loss 6.481\n",
            "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
            "Ep 4 (Step 000030): Train loss 5.407, Val loss 6.472\n",
            "Ep 4 (Step 000035): Train loss 5.281, Val loss 6.467\n",
            "Every effort moves you the a a a a a of theis to the \" a.                                    \n",
            "Ep 5 (Step 000040): Train loss 4.888, Val loss 6.452\n",
            "Every effort moves you, one of the picture the picture--as his the picture.                                     \n",
            "Ep 6 (Step 000045): Train loss 4.467, Val loss 6.295\n",
            "Ep 6 (Step 000050): Train loss 4.028, Val loss 6.237\n",
            "Every effort moves you. \"I a little the donkey--I, with a little. I had been--and, with a little  \"I had been. I had been--and it's the honour to me, and I had been. I had\n",
            "Ep 7 (Step 000055): Train loss 4.171, Val loss 6.224\n",
            "Ep 7 (Step 000060): Train loss 3.362, Val loss 6.139\n",
            "Every effort moves you know it's \"Yes--I had been to the fact of the last word.         \"I was the picture--as Jack's the donkey.  \"I up and down, and he was his\n",
            "Ep 8 (Step 000065): Train loss 2.936, Val loss 6.119\n",
            "Ep 8 (Step 000070): Train loss 2.586, Val loss 6.189\n",
            "Every effort moves you know the fact, and pushed one of the deep arm-chairs.                      \"Oh, I had the donkey.      \n",
            "Ep 9 (Step 000075): Train loss 2.213, Val loss 6.148\n",
            "Ep 9 (Step 000080): Train loss 1.857, Val loss 6.199\n",
            "Every effort moves you know,\" was not that my hostess was--I had a little of a and in the picture, with a little    \"Oh, in the head to me.   \"I looked, and it.   \n",
            "Ep 10 (Step 000085): Train loss 1.454, Val loss 6.229\n",
            "Every effort moves you know,\" was not that my hostess was \"interesting\": on that point I had been--and by me to me to have to see a smile behind his painting.      \"I had a little the room, with a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "id": "WkB3oAIQLr-c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "3638ec22-6f74-44a0-c872-60f070faafb1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decoding strategies to control randomness"
      ],
      "metadata": {
        "id": "EEGJApHjMcpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(\"cpu\")\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "MYWER_aGMgia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5457bd18-82ec-4dae-a8f4-1235b35daaca"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "token_ids = generate_text_simple(\n",
        "model=model,\n",
        "idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "max_new_tokens=25,\n",
        "context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "hkmgjHs-OkMa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53bf6ac0-6533-4129-c1cc-c5baf07ea767"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you know,\" was not that my hostess was \"interesting\": on that point I had been--and by me to me to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Temperature scaling"
      ],
      "metadata": {
        "id": "xVhLG3LsPH6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {\n",
        "\"closer\": 0,\n",
        "\"every\": 1,\n",
        "\"effort\": 2,\n",
        "\"forward\": 3,\n",
        "\"inches\": 4,\n",
        "\"moves\": 5,\n",
        "\"pizza\": 6,\n",
        "\"toward\": 7,\n",
        "\"you\": 8,\n",
        "}\n",
        "inverse_vocab = {v: k for k, v in vocab.items()}"
      ],
      "metadata": {
        "id": "71XUOgNrOtfI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_token_logits = torch.tensor(\n",
        "[4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
        ")\n",
        "probas = torch.softmax(next_token_logits, dim=0)\n",
        "next_token_id = torch.argmax(probas).item()\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "id": "B8Na80VdP5Tx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70c46d31-89ed-4403-ffb9-83cd81482009"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "id": "xwOU6OVXRj3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18079449-a06d-49dd-e3f1-26447fca717c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_sampled_tokens(probas):\n",
        "  torch.manual_seed(123)\n",
        "  sample = [torch.multinomial(probas, num_samples =1).item() for i in range(1_000)]\n",
        "  sampled_ids = torch.bincount(torch.tensor(sample))\n",
        "  for i, freq in enumerate(sampled_ids):\n",
        "    print(f\"{freq} x {inverse_vocab[i]}\")\n",
        "\n",
        "print_sampled_tokens(probas)"
      ],
      "metadata": {
        "id": "bggWn5ehS2XM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6f855f-6916-4547-b5f2-47397036b51f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71 x closer\n",
            "2 x every\n",
            "0 x effort\n",
            "544 x forward\n",
            "2 x inches\n",
            "1 x moves\n",
            "0 x pizza\n",
            "376 x toward\n",
            "4 x you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_with_temperature(logits, temperature):\n",
        "  scaled_logits = logits / temperature\n",
        "  return torch.softmax(scaled_logits, dim=0)"
      ],
      "metadata": {
        "id": "m4mNhjSsWJUX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temperatures = [1, 0.1, 5]\n",
        "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
        "x = torch.arange(len(vocab))\n",
        "bar_width = 0.15\n",
        "fig, ax = plt.subplots(figsize=(5, 3))\n",
        "for i, T in enumerate(temperatures):\n",
        "  rects = ax.bar(x+ i*bar_width, scaled_probas[i],\n",
        "                 bar_width, label=f\"T={T}\")\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3QNKrF6jWLQq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "3f49115f-2f26-4364-d78f-9379d95d8bea"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top-k sampling"
      ],
      "metadata": {
        "id": "Oas_q9PvXyD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = 3\n",
        "top_logits, top_pos = torch.topk(next_token_logits, k=top_k)\n",
        "print(\"Top logits:\", top_logits)\n",
        "print(\"Top positions:\", top_pos)"
      ],
      "metadata": {
        "id": "QOv5iXTlX1Ci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f772d8b2-67ff-4971-a8a5-a9098e631765"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
            "Top positions: tensor([3, 7, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_logits = torch.where(\n",
        "condition=next_token_logits < top_logits[-1],\n",
        "input=torch.tensor(float('-inf')),\n",
        "other=next_token_logits\n",
        ")\n",
        "print(new_logits)"
      ],
      "metadata": {
        "id": "23FdKXBdbAQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680dd31a-7e5b-4754-e836-f067e523dcc6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topk_probas = torch.softmax(new_logits, dim=0)\n",
        "print(topk_probas)"
      ],
      "metadata": {
        "id": "D3mLRVFRbAy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b115efb-9134-4747-df57-1770178f8aa3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "v_hqsMaFbHAS"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "token_ids = generate(\n",
        "model=model,\n",
        "idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "max_new_tokens=15,\n",
        "context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "top_k=25,\n",
        "temperature=1.4\n",
        ")\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "nF_Xl8BJcEIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40a7d0c7-99c1-4934-93a0-8163258aa5ad"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you know began to happen a hint a little it was no\n",
            "\"I was\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and load model\n"
      ],
      "metadata": {
        "id": "luNGy0YLdbzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")"
      ],
      "metadata": {
        "id": "XvaAYlkPdeeH"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "gmtz1q7fdmfp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ee0068d-b3f7-4955-f6b8-cd22e8e63ea3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "\"model_state_dict\": model.state_dict(),\n",
        "\"optimizer_state_dict\": optimizer.state_dict(),\n",
        "},\n",
        "\"model_and_optimizer.pth\"\n",
        ")"
      ],
      "metadata": {
        "id": "BO-3LY4ed2fq"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train();"
      ],
      "metadata": {
        "id": "Md-j5Jhod859"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading pretrained weights from OpenAI"
      ],
      "metadata": {
        "id": "JH5t-bkbeUsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow>=2.15.0 tqdm>=4.66"
      ],
      "metadata": {
        "id": "sEYz1RfbeYVZ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version\n",
        "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
        "print(\"tqdm version:\", version(\"tqdm\"))"
      ],
      "metadata": {
        "id": "zkz7qk1ynuF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2029ac3c-1661-4c75-d27b-50881f687301"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "tqdm version: 4.67.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "url = (\n",
        "\"https://raw.githubusercontent.com/rasbt/\"\n",
        "\"LLMs-from-scratch/main/ch05/\"\n",
        "\"01_main-chapter-code/gpt_download.py\"\n",
        ")\n",
        "filename = url.split('/')[-1]\n",
        "urllib.request.urlretrieve(url, filename)"
      ],
      "metadata": {
        "id": "QqyRvocPhM-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ec359c-e683-45fb-81dd-f7d4fb72bbbd"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('gpt_download.py', <http.client.HTTPMessage at 0x7eeaa7107f10>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
      ],
      "metadata": {
        "id": "JJEVO9AvhP0t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f30c75c3-6c67-4633-a62f-51ec34661e1c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 97.0kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.17MiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 136kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [01:36<00:00, 5.16MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 6.63MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 622kiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 587kiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Settings:\", settings)\n",
        "print(\"Parameter dictionary keys:\", params.keys())\n",
        "print(params[\"wte\"])\n",
        "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
      ],
      "metadata": {
        "id": "_k9h5rHShzrQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7cb3d7a-f2ce-4409-9ad7-9e1e79695efd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
            "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
            "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
            "   0.04531523]\n",
            " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
            "   0.04318958]\n",
            " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
            "  -0.08785918]\n",
            " ...\n",
            " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
            "  -0.06952604]\n",
            " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
            "  -0.02245961]\n",
            " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
            "   0.12067825]]\n",
            "Token embedding weight tensor dimensions: (50257, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model configurations in a dictionary for compactness\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "# Copy the base configuration and update with specific model settings\n",
        "model_name = \"gpt2-small (124M)\"  # Example model name\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "NEW_CONFIG.update(model_configs[model_name])\n",
        "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
        "\n",
        "gpt = GPTModel(NEW_CONFIG)\n",
        "gpt.eval();"
      ],
      "metadata": {
        "id": "rAZ9GtTkiSu8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(NEW_CONFIG)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D97oxXjSudHf",
        "outputId": "cbe7cab8-c643-4cc8-a509-003851526ba3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'vocab_size': 50257, 'context_length': 1024, 'emb_dim': 768, 'n_layers': 12, 'n_heads': 12, 'drop_rate': 0.1, 'qkv_bias': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right, dtype=left.dtype))\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])  # position embeddings\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])  # token embeddings\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        block = params[\"blocks\"][b]\n",
        "\n",
        "        # Attention QKV weights and biases\n",
        "        q_w, k_w, v_w = np.split(block[\"attn\"][\"c_attn\"][\"w\"], 3, axis=-1)\n",
        "        q_b, k_b, v_b = np.split(block[\"attn\"][\"c_attn\"][\"b\"], 3, axis=-1)\n",
        "\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight   = assign(gpt.trf_blocks[b].att.W_key.weight,   k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias   = assign(gpt.trf_blocks[b].att.W_key.bias,   k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        # Attention output projection\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight, block[\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias, block[\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        # Feed-forward network\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight, block[\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias, block[\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight, block[\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias, block[\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        # LayerNorm 1\n",
        "        gpt.trf_blocks[b].norm1.weight = assign(\n",
        "            gpt.trf_blocks[b].norm1.weight, block[\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.bias = assign(\n",
        "            gpt.trf_blocks[b].norm1.bias, block[\"ln_1\"][\"b\"])\n",
        "\n",
        "        # LayerNorm 2\n",
        "        gpt.trf_blocks[b].norm2.weight = assign(\n",
        "            gpt.trf_blocks[b].norm2.weight, block[\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.bias = assign(\n",
        "            gpt.trf_blocks[b].norm2.bias, block[\"ln_2\"][\"b\"])\n",
        "\n",
        "    # Final LayerNorm\n",
        "    gpt.final_norm.weight = assign(gpt.final_norm.weight, params[\"g\"])\n",
        "    gpt.final_norm.bias = assign(gpt.final_norm.bias, params[\"b\"])\n",
        "\n",
        "    # Output head (tied with token embedding)\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n"
      ],
      "metadata": {
        "id": "5MbaZxpLjDww"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_weights_into_gpt(gpt, params)\n",
        "gpt.eval()\n",
        "gpt.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpmHvikRuuNk",
        "outputId": "3730746f-50f5-4fe0-8e61-b3cc54790b60"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
        "    max_new_tokens=25,\n",
        "    context_size=NEW_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=1.5\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "dCTH7BWIjuTA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96113ba6-8c27-448d-b328-c27952c01bfd"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you as far as the hand can go until the end of your turn unless something happens\n",
            "\n",
            "This would remove you from a battle\n"
          ]
        }
      ]
    }
  ]
}